{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install all dependencies\n",
    "# !pip install openai instructor pydantic tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing NcML using GPT4\n",
    "\n",
    "This notebook demonstrates how to use GPT4 to extract metadata from `ncml` files drawn from Dataverse datasets. Each `ncml` file has been obtained from the [Harvard Dataverse](https://dataverse.harvard.edu/) repository, a platform that facilitates sharing and preservation of research data. For extraction, we've utilized the [Dataverse API](https://guides.dataverse.org/en/latest/api/index.html) and saved the output as an XML file.\n",
    "\n",
    "Our goal with this notebook is to leverage GPT4 to extract metadata from `ncml` data and convert it into a structured format using [`instructor`](https://jxnl.github.io/instructor/) compliant with a questionnaire model, implemented through [`pydantic`](https://docs.pydantic.dev/latest/) classes. This approach allows us to obtain metadata from varying ke-value data found in `ncml`, which can be further analyzed and scaled with ease.\n",
    "\n",
    "Please note, in order to use this notebook it is necessary to provide an OpenAI API Token via the `OPENAPI_API_KEY` environment variable and sufficient credits to use GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import instructor\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "from model.questionaires import ResponseModel\n",
    "\n",
    "instructor.patch(openai.OpenAI())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmls = {}\n",
    "for path in glob.glob(\"../data/ncml-files/*.xml\"):\n",
    "    fname = os.path.basename(path)\n",
    "    ncmls[fname] = {\n",
    "        \"content\": open(path).read(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [21:39<00:00,  9.69s/it]\n"
     ]
    }
   ],
   "source": [
    "system_msg = \"You are a helpful assistant who understands geospatial sciences, NetCDF Markup Language (NcML) and how to parse XML.\"\n",
    "\n",
    "for key in tqdm.tqdm(ncmls.keys()):\n",
    "    \n",
    "    if ncmls[key].get(\"response\") is not None:\n",
    "        continue\n",
    "    \n",
    "    user_msg = (\n",
    "        \"Extract metadata from the following NetCDF Markup Language file (XML encoded): \"\n",
    "        + ncmls[key][\"content\"]\n",
    "    )\n",
    "    \n",
    "    response: ResponseModel = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        response_model=ResponseModel,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    ncmls[key][\"response\"] = response.model_dump(exclude_unset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/gpt4_on_ncml.json\", \"w\") as f:\n",
    "    json.dump(ncmls, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2sdrdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
